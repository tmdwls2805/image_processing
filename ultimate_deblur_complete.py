import cv2
import numpy as np
import os
from scipy import ndimage

class UltimateDeblur:
    def __init__(self):
        pass
    
    def estimate_noise_level(self, image):
        """ë…¸ì´ì¦ˆ ë ˆë²¨ ìë™ ì¶”ì •"""
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]) / 8.0
        filtered = cv2.filter2D(gray.astype(np.float64), -1, kernel)
        noise_sigma = 1.4826 * np.median(np.abs(filtered - np.median(filtered)))
        return max(noise_sigma, 1.0)
    
    def richardson_lucy_fast(self, image, psf, iterations=20):
        """ë¹ ë¥¸ Richardson-Lucy"""
        estimate = image.copy().astype(np.float64)
        psf_flipped = np.flipud(np.fliplr(psf))
        
        for _ in range(iterations):
            conv_estimate = ndimage.convolve(estimate, psf, mode='wrap')
            conv_estimate = np.maximum(conv_estimate, 1e-12)
            ratio = image.astype(np.float64) / conv_estimate
            correction = ndimage.convolve(ratio, psf_flipped, mode='wrap')
            estimate = estimate * correction
            estimate = np.maximum(estimate, 0)
        
        return estimate
    
    def estimate_smart_psf(self, image, psf_size=25):
        """ìŠ¤ë§ˆíŠ¸ PSF ì¶”ì •"""
        # Edge-based ë°©ë²•
        edges = cv2.Canny(image, 50, 150)
        angles1 = []
        for angle in range(0, 180, 5):
            rotated = ndimage.rotate(edges, angle, reshape=False)
            projection = np.sum(rotated, axis=0)
            angles1.append(np.var(projection))
        
        best_angle1 = np.argmax(angles1) * 5 + 90
        
        # Gradient-based ë°©ë²•
        grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
        angles = np.arctan2(grad_y, grad_x)
        hist, bins = np.histogram(angles, bins=180)
        best_angle2 = np.degrees(bins[np.argmax(hist)])
        
        # í‰ê· 
        final_angle = np.radians((best_angle1 + best_angle2) / 2)
        
        # ê¸¸ì´ ì¶”ì •
        blur_strength = np.std(cv2.Laplacian(image, cv2.CV_64F)) / 255.0
        length = int(max(5, min(psf_size-2, blur_strength * 25)))
        
        # PSF ìƒì„±
        psf = np.zeros((psf_size, psf_size))
        center = psf_size // 2
        
        for i in range(length):
            x = int(center + (i - length//2) * np.cos(final_angle))
            y = int(center + (i - length//2) * np.sin(final_angle))
            if 0 <= x < psf_size and 0 <= y < psf_size:
                psf[y, x] = 1.0
        
        if np.sum(psf) > 0:
            psf /= np.sum(psf)
            psf = ndimage.gaussian_filter(psf, sigma=0.5)
            psf /= np.sum(psf)
        
        return psf
    
    def non_local_means_deblur(self, image, psf, h=10):
        """Non-Local Means ë””ë¸”ëŸ¬ë§"""
        print("  Non-Local Means ë””ë¸”ëŸ¬ë§...")
        
        if len(image.shape) == 3:
            result = np.zeros_like(image, dtype=np.float64)
            for c in range(3):
                # ì´ˆê¸° ë””ë¸”ëŸ¬ë§
                channel = image[:, :, c].astype(np.float64) / 255.0
                deblurred = self.richardson_lucy_fast(channel, psf, 15)
                
                # Non-local means ì •ì œ
                deblurred_uint8 = (deblurred * 255).astype(np.uint8)
                refined = cv2.fastNlMeansDenoising(deblurred_uint8, None, h, 7, 21)
                result[:, :, c] = refined.astype(np.float64)
            
            return result
        else:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
            image_norm = image.astype(np.float64) / 255.0
            deblurred = self.richardson_lucy_fast(image_norm, psf, 15)
            deblurred_uint8 = (deblurred * 255).astype(np.uint8)
            refined = cv2.fastNlMeansDenoising(deblurred_uint8, None, h, 7, 21)
            return refined.astype(np.float64)
    
    def tv_l1_deconvolution(self, image, psf, lambda_tv=0.02, iterations=50):
        """Total Variation L1 ë””ì»¨ë³¼ë£¨ì…˜"""
        print("  TV-L1 ì •ê·œí™” ë””ì»¨ë³¼ë£¨ì…˜...")
        
        if len(image.shape) == 3:
            result = np.zeros_like(image, dtype=np.float64)
            for c in range(3):
                result[:, :, c] = self._tv_l1_channel(image[:, :, c], psf, lambda_tv, iterations)
            return result
        else:
            return self._tv_l1_channel(image, psf, lambda_tv, iterations)
    
    def _tv_l1_channel(self, channel, psf, lambda_tv, iterations):
        """ë‹¨ì¼ ì±„ë„ TV-L1"""
        channel_norm = channel.astype(np.float64) / 255.0
        x = channel_norm.copy()
        
        # TV ì •ê·œí™”ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë°˜ë³µ
        for i in range(iterations):
            # ë°ì´í„° ì¶©ì‹¤ë„ í•­
            conv_x = ndimage.convolve(x, psf, mode='wrap')
            residual = conv_x - channel_norm
            conv_residual = ndimage.convolve(residual, np.flipud(np.fliplr(psf)), mode='wrap')
            
            # Gradient descent step
            grad_x = np.gradient(x, axis=1)
            grad_y = np.gradient(x, axis=0)
            
            # TV regularization (ê°„ë‹¨í•œ ê·¼ì‚¬)
            tv_term = ndimage.laplace(x)
            
            # ì—…ë°ì´íŠ¸
            x = x - 0.01 * (conv_residual + lambda_tv * tv_term)
            x = np.maximum(x, 0)  # ìŒìˆ˜ ë°©ì§€
            
            if i % 10 == 0:
                print(f"    TV-L1 ë°˜ë³µ {i+1}/{iterations}")
        
        return x * 255.0
    
    def bm3d_style_deblur(self, image, psf):
        """BM3D ìŠ¤íƒ€ì¼ ë””ë¸”ëŸ¬ë§"""
        print("  BM3D ìŠ¤íƒ€ì¼ 3D ë³€í™˜...")
        
        if len(image.shape) == 3:
            result = np.zeros_like(image, dtype=np.float64)
            for c in range(3):
                # ì´ˆê¸° ë””ë¸”ëŸ¬ë§
                channel = image[:, :, c].astype(np.float64) / 255.0
                deblurred = self.richardson_lucy_fast(channel, psf, 15)
                
                # ë¸”ë¡ ê¸°ë°˜ ë””ë…¸ì´ì§• (BM3D ê°„ì†Œí™”)
                deblurred_uint8 = (deblurred * 255).astype(np.uint8)
                
                # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì²˜ë¦¬
                scales = [1.0, 0.8, 0.6]
                enhanced = np.zeros_like(deblurred_uint8, dtype=np.float64)
                
                for scale in scales:
                    if scale < 1.0:
                        h, w = deblurred_uint8.shape
                        small = cv2.resize(deblurred_uint8, (int(w*scale), int(h*scale)))
                        processed = cv2.bilateralFilter(small, 9, 75, 75)
                        processed = cv2.resize(processed, (w, h))
                    else:
                        processed = cv2.bilateralFilter(deblurred_uint8, 9, 75, 75)
                    
                    enhanced += processed.astype(np.float64) * scale
                
                enhanced /= sum(scales)
                result[:, :, c] = enhanced
            
            return result
        else:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì²˜ë¦¬
            image_norm = image.astype(np.float64) / 255.0
            deblurred = self.richardson_lucy_fast(image_norm, psf, 15)
            deblurred_uint8 = (deblurred * 255).astype(np.uint8)
            
            enhanced = cv2.bilateralFilter(deblurred_uint8, 9, 75, 75)
            return enhanced.astype(np.float64)
    
    def dark_channel_deblur(self, image, psf):
        """Dark Channel Prior ë””ë¸”ëŸ¬ë§"""
        print("  Dark Channel Prior...")
        
        if len(image.shape) != 3:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        
        # Dark channel ê³„ì‚°
        min_channel = np.min(image, axis=2)
        kernel = np.ones((15, 15), np.uint8)
        dark_channel = cv2.erode(min_channel, kernel)
        
        # Atmospheric light ì¶”ì •
        flat_dark = dark_channel.flatten()
        indices = np.argsort(flat_dark)[-100:]  # ìƒìœ„ 100ê°œ í”½ì…€
        
        A = np.zeros(3)
        for c in range(3):
            flat_channel = image[:, :, c].flatten()
            A[c] = np.max(flat_channel[indices])
        
        # Transmission ì¶”ì •
        omega = 0.95
        transmission = np.zeros_like(dark_channel, dtype=np.float64)
        for c in range(3):
            transmission = np.maximum(transmission, image[:, :, c] / (A[c] + 1e-8))
        
        transmission = 1 - omega * (1 - transmission / 255.0)
        transmission = np.maximum(transmission, 0.1)
        
        # ë³µì›
        J = np.zeros_like(image, dtype=np.float64)
        for c in range(3):
            J[:, :, c] = (image[:, :, c] - A[c]) / transmission + A[c]
        
        J = np.clip(J, 0, 255)
        
        # ë””ë¸”ëŸ¬ë§ ì ìš©
        deblurred = np.zeros_like(J)
        for c in range(3):
            deblurred[:, :, c] = self.richardson_lucy_fast(J[:, :, c] / 255.0, psf, 20) * 255.0
        
        return deblurred
    
    def intelligent_hybrid_deblur(self, image):
        """ğŸ† ì§€ëŠ¥ì  í•˜ì´ë¸Œë¦¬ë“œ - ìµœê³ ì˜ ëª¨ë“  ê¸°ë²• ê²°í•©"""
        print("ğŸš€ ì§€ëŠ¥ì  í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ...")
        
        # PSF ì¶”ì •
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        psf = self.estimate_smart_psf(gray, 25)
        noise_level = self.estimate_noise_level(image)
        print(f"  ë…¸ì´ì¦ˆ ë ˆë²¨: {noise_level:.2f}")
        
        # 1ë‹¨ê³„: BM3D ìŠ¤íƒ€ì¼ ì´ˆê¸° ì²˜ë¦¬
        print("1ë‹¨ê³„: BM3D ìŠ¤íƒ€ì¼ ì²˜ë¦¬")
        result1 = self.bm3d_style_deblur(image, psf)
        
        # 2ë‹¨ê³„: Non-Local Means ì •ì œ
        print("2ë‹¨ê³„: Non-Local Means ì •ì œ")
        h_param = max(noise_level * 0.8, 8)
        result1_uint8 = np.clip(result1, 0, 255).astype(np.uint8)
        result2 = self.non_local_means_deblur(result1_uint8, psf, int(h_param))
        
        # 3ë‹¨ê³„: TV-L1 ìµœì¢… ì •ì œ
        print("3ë‹¨ê³„: TV-L1 ì •ê·œí™”")
        lambda_tv = 0.01 if noise_level > 15 else 0.005
        result2_uint8 = np.clip(result2, 0, 255).astype(np.uint8)
        result3 = self.tv_l1_deconvolution(result2_uint8, psf, lambda_tv, 30)
        
        # 4ë‹¨ê³„: ìµœì¢… ì„ ëª…í™”
        print("4ë‹¨ê³„: ìµœì¢… ì„ ëª…í™”")
        final_result = np.clip(result3, 0, 255).astype(np.uint8)
        
        # ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
        if len(final_result.shape) == 3:
            lab = cv2.cvtColor(final_result, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
            l = clahe.apply(l)
            final_result = cv2.merge([l, a, b])
            final_result = cv2.cvtColor(final_result, cv2.COLOR_LAB2BGR)
        
        # ìµœì¢… ìƒ¤í”„ë‹
        kernel = np.array([[-0.5, -1, -0.5], [-1, 7, -1], [-0.5, -1, -0.5]]) / 3
        final_result = cv2.filter2D(final_result, -1, kernel)
        
        return np.clip(final_result, 0, 255).astype(np.uint8)
    
    def process_image(self, image_path, method='hybrid', output_path=None):
        """ìµœê³  ì„±ëŠ¥ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        try:
            print(f"ğŸ“ ì´ë¯¸ì§€ ë¡œë“œ: {image_path}")
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            
            print(f"ğŸ¯ ë°©ë²•: {method}")
            
            if method == 'nlm':
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                else:
                    gray = image
                psf = self.estimate_smart_psf(gray, 21)
                result = self.non_local_means_deblur(image, psf)
                
            elif method == 'tv_l1':
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                else:
                    gray = image
                psf = self.estimate_smart_psf(gray, 21)
                result = self.tv_l1_deconvolution(image, psf)
                
            elif method == 'bm3d':
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                else:
                    gray = image
                psf = self.estimate_smart_psf(gray, 21)
                result = self.bm3d_style_deblur(image, psf)
                
            elif method == 'dark_channel':
                if len(image.shape) == 3:
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                else:
                    gray = image
                psf = self.estimate_smart_psf(gray, 21)
                result = self.dark_channel_deblur(image, psf)
                
            elif method == 'hybrid':
                result = self.intelligent_hybrid_deblur(image)
            
            else:
                print("â“ ì•Œ ìˆ˜ ì—†ëŠ” ë°©ë²•, hybrid ì‚¬ìš©")
                result = self.intelligent_hybrid_deblur(image)
            
            # ìµœì¢… ê²°ê³¼
            result = np.clip(result, 0, 255).astype(np.uint8)
            
            # ì¶œë ¥ ê²½ë¡œ
            if output_path is None:
                base_name = os.path.splitext(image_path)[0]
                ext = os.path.splitext(image_path)[1]
                output_path = f"{base_name}_ultimate_{method}{ext}"
            
            cv2.imwrite(output_path, result)
            print(f"âœ… ì™„ë£Œ: {output_path}")
            
            return output_path
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

def main():
    image_path = "C:/develop/vision-test/file/girl.jpg"
    processor = UltimateDeblur()
    
    print("=== ğŸš€ ìµœê³  ì„±ëŠ¥ ë””ë¸”ëŸ¬ë§ ì‹œìŠ¤í…œ ===\n")
    
    # ìµœê³ ì˜ ë°©ë²•ë“¤
    methods = [
        ('nlm', 'ğŸ”§ Non-Local Means (íŒ¨ì¹˜ ìœ ì‚¬ì„±)'),
        ('tv_l1', 'ğŸ“ TV-L1 ì •ê·œí™” (ìŠ¤íŒŒìŠ¤ ê·¸ë˜ë””ì–¸íŠ¸)'), 
        ('bm3d', 'ğŸ›ï¸ BM3D ìŠ¤íƒ€ì¼ (3D ë³€í™˜)'),
        ('dark_channel', 'ğŸŒ«ï¸ Dark Channel Prior'),
        ('hybrid', 'ğŸ† ì§€ëŠ¥ì  í•˜ì´ë¸Œë¦¬ë“œ (ìµœê³ ì˜ ëª¨ë“  ê¸°ë²•)')
    ]
    
    results = []
    
    for method, description in methods:
        print(f"\n--- {description} ---")
        result = processor.process_image(image_path, method=method)
        if result:
            results.append(result)
            print(f"âœ… ì„±ê³µ: {os.path.basename(result)}")
        else:
            print("âŒ ì‹¤íŒ¨")
    
    print(f"\n=== ğŸ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ! ===")
    print("ğŸ“‚ ìƒì„±ëœ íŒŒì¼ë“¤:")
    for result in results:
        print(f"   ğŸ“„ {os.path.basename(result)}")
    
    print(f"\nğŸ’¡ ì¶”ì²œ: 'hybrid' ë°©ë²•ì´ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤!")
    print("ğŸ”¥ ì´ ë°©ë²•ë“¤ì€ ìµœì‹  ë…¼ë¬¸ì˜ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤!")

if __name__ == "__main__":
    main()